{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["bnEIPxjWWZaX","vEU-jI0jrkuK","oGGytWkMk3Bv","4azk01tQrtKw","_QLY5Z9fr9ig","XHXcGOM8CBIA","0X35RrTaszqe"],"authorship_tag":"ABX9TyOGrIircu7H2wHooQl2/bBm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **GPU Project: Parallel Differential Distinguisher**\n","\n","*   **Author:** Matteo Onger\n","*   **Date:** July 2024"],"metadata":{"id":"gNIdCYybMQ6K"}},{"cell_type":"markdown","source":["**Documentation**:\n","*   [CUDA](https://docs.nvidia.com/cuda/cuda-c-programming-guide/contents.html)\n","*   [CuPy](https://docs.cupy.dev/en/latest/index.html)\n","*   [Numba](https://numba.readthedocs.io/en/stable/)\n","\n","**Notes**:\n","* To execute this notebook, GPU-equipped runtime is necessary.\n"],"metadata":{"id":"169kyXF1NaIY"}},{"cell_type":"markdown","source":["## **VM Setup**\n"],"metadata":{"id":"bnEIPxjWWZaX"}},{"cell_type":"code","source":["# download differential distinguisher code\n","# (incomplete repository, only necessary files)\n","!git clone https://github.com/MatteoOnger/GPU_Project.git\n","\n","# set working directory\n","%cd /content/GPU_Project/"],"metadata":{"id":"gmbw9xGvrBuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721489760527,"user_tz":-120,"elapsed":1934,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}},"outputId":"ed307f41-4e52-4410-e440-6eeed05d4141"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'GPU_Project'...\n","remote: Enumerating objects: 126, done.\u001b[K\n","remote: Counting objects: 100% (126/126), done.\u001b[K\n","remote: Compressing objects: 100% (86/86), done.\u001b[K\n","remote: Total 126 (delta 51), reused 87 (delta 27), pack-reused 0\u001b[K\n","Receiving objects: 100% (126/126), 250.27 KiB | 12.51 MiB/s, done.\n","Resolving deltas: 100% (51/51), done.\n","/content/GPU_Project\n"]}]},{"cell_type":"code","source":["# download and install NVIDIA Nsight Systems\n","##!wget https://developer.nvidia.com/downloads/assets/tools/secure/nsight-systems/2024_3/nsight-systems-2024.3.1_2024.3.1.75-1_amd64.deb\n","##!apt update\n","\n","##!apt install ./nsight-systems-2024.3.1_2024.3.1.75-1_amd64.deb\n","##!apt --fix-broken install\n","\n","##!rm ./nsight-systems-2024.3.1_2024.3.1.75-1_amd64.deb"],"metadata":{"id":"RQhXZl81WPLp","executionInfo":{"status":"ok","timestamp":1721489760527,"user_tz":-120,"elapsed":4,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## **Parallel Optimizer**"],"metadata":{"id":"x27dsghpXrkO"}},{"cell_type":"markdown","source":["### utils/filters.py"],"metadata":{"id":"vEU-jI0jrkuK"}},{"cell_type":"code","source":["%%writefile utils/filters.py\n","\"\"\"\n","Filters' implementations.\n","\"\"\"\n","# --------------------------------------------------------------------------- #\n","# NOTE:\n","#  A ``_d`` at the end of a variable name means that it is saved in the\n","#  device memory of the GPU currently in use.\n","# --------------------------------------------------------------------------- #\n","\n","import cupy as cp\n","import logging\n","\n","from math import ceil, exp, log\n","from numba import cuda\n","\n","\n","logger = logging.getLogger(\"autond2.\" + __name__)\n","\n","\n","# ---------------------- DEVICE FUNCTIONS ------------------\n","@cuda.jit(device=True)\n","def _fnv_32(arr :cp.ndarray) -> int:\n","    \"\"\"\n","    Fowler–Noll–Vo hash function.\n","    Compute a 32-bit hash value from an array of integers.\n","\n","    Parameters\n","    ----------\n","    ``arr``: cupy.ndarray of shape ``(N,)``\n","        Array of integers.\n","\n","    Returns\n","    -------\n","    int\n","        32-bit hash value.\n","\n","    See Also\n","    --------\n","    - Fowler–Noll–Vo: https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function.\n","    \"\"\"\n","    hval = 0x811c9dc5\n","    for a in arr:\n","        hval = (hval * 0x01000193) % (2**32)\n","        hval = hval ^ a\n","    return hval\n","\n","\n","@cuda.jit(device=True)\n","def _fnva_32(arr :cp.ndarray) -> int:\n","    \"\"\"\n","    Fowler–Noll–Vo hash function, version 'A'.\n","    Compute a 32-bit hash value from an array of integers.\n","\n","    Parameters\n","    ----------\n","    ``arr``: cupy.ndarray of shape ``(N,)``\n","        Array of integers.\n","\n","    Returns\n","    -------\n","    int\n","        32-bit hash value.\n","\n","    See Also\n","    --------\n","    - Fowler–Noll–Vo: https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function.\n","    \"\"\"\n","    hval = 0x811c9dc5\n","    for a in arr:\n","        hval = hval ^ a\n","        hval = (hval * 0x01000193) % (2**32)\n","    return hval\n","\n","\n","@cuda.jit(device=True)\n","def _hash_i(filter_size :int, i :int, arr :cp.ndarray) -> int:\n","    \"\"\"\n","    Compute the i-th hash value of the given array of integers for the considered filter.\n","\n","    Parameters\n","    ----------\n","    ``filter_size``: int\n","        Filter size in bits.\n","    ``i``: int\n","        Index of the hash function.\n","        ``0 <= i < num_hashes``\n","    ``arr``: cupy.ndarray of shape ``(N,)``\n","        Array of integers.\n","\n","    Returns\n","    -------\n","    ``h``: int\n","        i-th hash value.\n","        ``0 <= h < filter_size``\n","\n","    Notes\n","    -----\n","    Instead of using many different hash functions, two digests are linearly combined. It can be shown that, given certain conditions on the filter size and on the functions used, this does not result in a higher probability of error.\n","\n","    See Also\n","    --------\n","    - Original paper: https://www.eecs.harvard.edu/~michaelm/postscripts/tr-02-05.pdf.\n","    \"\"\"\n","    return (_fnv_32(arr) * i + _fnva_32(arr)) % filter_size\n","\n","\n","# ---------------------- KERNELS ---------------------------\n","@cuda.jit()\n","def _insert_new_elements(filter_size :int, word_size :int, num_hashes :int, filter :cp.ndarray, len_arr :int, arr :cp.ndarray, out :cp.ndarray):\n","    \"\"\"\n","    Insert new elements in the Bloom filter.\n","    The array ``out`` will contain a 1 in the i-th position iif the i-th element of ``arr`` was first seen now, 0 otherwise.\n","\n","    Grid & Blocks: one thread for each hash value to compute for each element in ``arr``.\n","\n","    Parameters\n","    ----------\n","    ``filter_size``: int\n","        Filter size in bits.\n","    ``word_size``: int\n","        Filter's word size in bits.\n","    ``num_hashes``: int\n","        Number of hash functions computed per element.\n","    ``filter``: cupy.ndarray of shape ``(num_words + 1,)``\n","        Bloom filter.\n","    ``len_arr``: int\n","        Number of elements to be inserted.\n","    ``arr``: cupy.ndarray of shape ``(len_arr, N)``\n","        Array of elements to be inserted. Each element is an array of ``N`` integers.\n","    ``out``: cupy.ndarray of shape ``(len_arr,)``\n","        Boolean array parallel to ``arr`` of newly discovered elements.\n","    \"\"\"\n","    x, y = cuda.grid(2)\n","\n","    if y < len_arr:\n","        h = _hash_i(filter_size, x, arr[y])\n","        word_idx, bit_idx = (h // word_size) + 1, h % word_size\n","\n","        # if h-th bit of the filter is zero\n","        while not(filter[word_idx] & (1 << bit_idx)):\n","            # and no one else is updating the filter\n","            if cuda.atomic.compare_and_swap(filter, 0, 1) == 0:\n","                cuda.threadfence()\n","\n","                # update the filter\n","                for i in range(0, num_hashes):\n","                    h = _hash_i(filter_size, i, arr[y])\n","                    word_idx,  bit_idx= (h // word_size) + 1, h % word_size\n","                    filter[word_idx] |=  (1 << bit_idx)\n","                out[y] = 1\n","\n","                cuda.threadfence()\n","                cuda.atomic.exch(filter, 0, 0)\n","                break\n","    return\n","\n","\n","# ---------------------- CLASSES ---------------------------\n","class BloomFilterGPU():\n","    \"\"\"\n","    Implementation of a simple Bloom filter on the GPU side.\n","    \"\"\"\n","    def __init__(self, num_hashes :int, filter_size :int):\n","        \"\"\"\n","        Create a new filter.\n","\n","        Parameters\n","        ----------\n","        ``num_hashes``: int\n","            Number of hash functions used.\n","        ``filter_size``: int\n","            Filter size in bits.\n","\n","        Notes\n","        -----\n","        For efficency reason the filter size should be a multiple of the word size, that is 64 bits.\n","        \"\"\"\n","        self.num_hashes = num_hashes\n","\n","        self.filter_size = filter_size\n","        self.word_size = cp.iinfo(cp.uint64).bits\n","        self.num_words = ceil(self.filter_size / self.word_size)\n","\n","        # the first word is used as a mutex to access the other words\n","        self.filter_d = cp.zeros(self.num_words + 1, dtype=cp.uint64)\n","\n","        n = ceil(filter_size/(-num_hashes/log(1-exp(log(0.01)/num_hashes))))\n","        logger.info(f\"filter {self} has an error probability of 1% after {n} entries\")\n","        return\n","\n","\n","    def get_block_size(self, tot_diffs :int) -> tuple[int, int]:\n","        \"\"\"\n","        Get the block size to be used given the total number of elements.\n","\n","        Parameters\n","        ----------\n","        ``tot_diffs``: int\n","            Total number of elements to be inserted.\n","\n","        Returns\n","        -------\n","        tuple[int, int]\n","            Blocks shape.\n","        \"\"\"\n","        return (self.num_hashes, min(1024 // self.num_hashes, tot_diffs))\n","\n","\n","    def get_grid_size(self, tot_diffs :int) -> tuple[int, int]:\n","        \"\"\"\n","        Get the grid size to be used given the total number of elements.\n","\n","        Parameters\n","        ----------\n","        ``tot_diffs``: int\n","            Total number of elements to be inserted.\n","\n","        Returns\n","        -------\n","        tuple[int, int]\n","            Grid shape.\n","        \"\"\"\n","        block_size = self.get_block_size(tot_diffs)\n","        return (1, ceil(tot_diffs / block_size[1]))\n","\n","\n","    def insert_new_elements(self, len_arr :int, arr_d :cp.ndarray, out_d :cp.ndarray) -> None:\n","        \"\"\"\n","        Insert new elements in the Bloom filter.\n","        The array ``out`` will contain a 1 in the i-th position iif the i-th element of ``arr`` was first seen now, 0 otherwise.\n","\n","        Parameters\n","        ----------\n","        ``len_arr``: int\n","            Number of elements to be inserted.\n","        ``arr_d``: cupy.ndarray of shape ``(len_arr, N)``\n","            Array of elements to be inserted. Each element is an array of ``N`` integers.\n","        ``out_d``: cupy.ndarray of shape ``(len_arr,)``\n","            Boolean array parallel to ``arr`` of newly discovered elements.\n","        \"\"\"\n","        block = self.get_block_size(len_arr)\n","        grid  = self.get_grid_size(len_arr)\n","\n","        _insert_new_elements[grid, block](\n","            self.filter_size,\n","            self.word_size,\n","            self.num_hashes,\n","            self.filter_d,\n","            len_arr,\n","            arr_d,\n","            out_d\n","        )\n","\n","        cuda.synchronize()\n","        return"],"metadata":{"id":"nAibgL4Bg0tn","executionInfo":{"status":"ok","timestamp":1721489760527,"user_tz":-120,"elapsed":3,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d70cd1f-be5e-493e-c508-ac041f2289bd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing utils/filters.py\n"]}]},{"cell_type":"markdown","source":["### evoalgs/evo.py"],"metadata":{"id":"oGGytWkMk3Bv"}},{"cell_type":"code","source":["%%writefile evoalgs/evo.py\n","\"\"\"\n","Implementation of the evolutionary algorithm originally used in the paper.\n","\"\"\"\n","# --------------------------------------------------------------------------- #\n","# NOTE:\n","#  A ``_d`` at the end of a variable name indicates that it is saved in the\n","#  device memory of the GPU currently in use.\n","# --------------------------------------------------------------------------- #\n","\n","import cupy as cp\n","import logging\n","import time\n","\n","from math import ceil\n","from numba import cuda\n","from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n","\n","from config import CipherParams, FitnessParams\n","from consts import Scenarios\n","from optimizer import evalute_multiple_differences\n","from utils.filters import BloomFilterGPU\n","\n","\n","logger = logging.getLogger(\"autond2.\" + __name__)\n","\n","\n","# ---------------------- CONSTANTS -------------------------\n","BLOOM_FILTER_SIZE :int = 262_144\n","\"\"\"\n","Size in bits of the Bloom filter used to check the input differences already found by the evolutionary algorithm.\n","\"\"\"\n","BLOOM_FILTER_NUM_HASHES :int = 8\n","\"\"\"\n","Number of hash functions used by the Bloom filter.\n","\"\"\"\n","GENERATION_SIZE :int = 32\n","\"\"\"\n","Size of each generation.\n","\"\"\"\n","MUTATION_PROB :float = 1\n","\"\"\"\n","Probability [0,1] of a mutation.\n","\"\"\"\n","NUM_GENERATIONS :int = 10\n","\"\"\"\n","Number of generations.\n","\"\"\"\n","OFFSPRING_SIZE :int = 128\n","\"\"\"\n","Size of the offspring for each generation. Must be bigger or equal than ``GENERATION_SIZE``.\n","\"\"\"\n","\n","\n","# ---------------------- KERNELS ---------------------------\n","def _apply_crossover_and_mutation(word_size :int, gen :cp.ndarray, kids :cp.ndarray):\n","    \"\"\"\n","    Apply crossover and mutation to the individuals in ``gen``.\n","\n","    Grid & Blocks: one thread for each kid wanted.\n","\n","    Parameters\n","    ----------\n","    ``word_size``: int\n","        Size in bits of the words that compose an individual.\n","    ``gen``: cupy.ndarray of shape ``(GENERATION_SIZE, num_words)``\n","        Individuals.\n","    ``kids``: cupy.ndarray of shape ``(OFFSPRING_SIZE, num_words)``\n","        New individuals.\n","    \"\"\"\n","    # trick to be able to allocate local arrays with size not known a priori\n","    @cuda.jit()\n","    def kernel(prng_states :cuda.devicearray, word_size :int, gen :cp.ndarray, kids :cp.ndarray):\n","        x = cuda.grid(1)\n","        if x < OFFSPRING_SIZE:\n","            # 'num_words' is defined in the calling function,\n","            # because local arrays cannot be allocated dynamically\n","            kid = cuda.local.array(num_words, gen.dtype)\n","\n","            # cross-over\n","            for i in range(num_words):\n","                # choose parents at random\n","                p1 = int(xoroshiro128p_uniform_float32(prng_states, x) * 1_000_000_000_000) % GENERATION_SIZE\n","                p2 = int(xoroshiro128p_uniform_float32(prng_states, x) * 1_000_000_000_000) % GENERATION_SIZE\n","                kid[i] = gen[p1][i] ^ gen[p2][i]\n","\n","            # mutation\n","            if xoroshiro128p_uniform_float32(prng_states, x) < MUTATION_PROB:\n","                word_idx = int(xoroshiro128p_uniform_float32(prng_states, x) *  1_000_000_000_000) % num_words\n","                bit_idx = int(xoroshiro128p_uniform_float32(prng_states, x) *  1_000_000_000_000) % word_size\n","                kid[word_idx] ^= (1 << bit_idx)\n","\n","            # store the new kid\n","            for i in range(num_words):\n","                kids[x][i] = kid[i]\n","        return\n","\n","    num_words = gen.shape[1]\n","    prng_states = create_xoroshiro128p_states(OFFSPRING_SIZE, seed=time.time())\n","    kernel[ceil(OFFSPRING_SIZE / 1024), min(1024, OFFSPRING_SIZE)](prng_states, word_size, gen, kids)\n","    return\n","\n","\n","# ---------------------- FUNCTIONS -------------------------\n","def evolve_gpu(scenario :Scenarios, num_round :int, cipher :CipherParams, fitness :FitnessParams) -> tuple[cp.ndarray, cp.ndarray]:\n","    \"\"\"\n","    Find good differences for the given round of encryption.\n","\n","    Parameters\n","    ----------\n","    ``scenario``: consts.Scenarios\n","        Attack scenario.\n","    ``num_round``: int\n","        Number of rounds to performe during encryption.\n","    ``cipher``: config.CipherParams\n","        Cipher parameters.\n","    ``fitness``: config.FitnessParams\n","        Fitness parameters.\n","\n","    Returns\n","    -------\n","    ``(gen_d, scores_d)``: tuple[cupy.ndarray, cupy.ndarray] of shapes ``(GENERATION_SIZE, num_words)`` and ``(GENERATION_SIZE,)``\n","        Best individuals found and their scores.\n","    \"\"\"\n","    if OFFSPRING_SIZE < GENERATION_SIZE:\n","        raise ValueError(\"``OFFSPRING_SIZE`` must be bigger or equal than ``GENERATION_SIZE``\")\n","\n","    num_words = cipher.plain_size if scenario == Scenarios.SINGLE_KEY else cipher.plain_size + cipher.key_size\n","    filter_d = BloomFilterGPU(BLOOM_FILTER_NUM_HASHES, BLOOM_FILTER_SIZE)\n","\n","    gen_d = cp.empty((GENERATION_SIZE, num_words), dtype=cipher.word_type)\n","    scores_d = cp.zeros(GENERATION_SIZE, dtype=cp.float32)\n","\n","    for i in range(NUM_GENERATIONS):\n","        kids_d = None\n","        if i == 0:\n","            # first generation is randomly generated\n","            kids_d = cp.random.randint(1 << cipher.word_size, size=(OFFSPRING_SIZE, num_words), dtype=cipher.word_type)\n","        else:\n","            # generate children from the previous generation\n","            kids_d = cp.empty((OFFSPRING_SIZE, num_words), dtype=cipher.word_type)\n","            _apply_crossover_and_mutation(cipher.word_size, gen_d, kids_d)\n","            cuda.synchronize()\n","\n","        # i-th entry will be '1' iif the individual 'kids_d[i]' has not already been seen\n","        positions_d = cp.zeros(OFFSPRING_SIZE, dtype=cp.int8)\n","        filter_d.insert_new_elements(OFFSPRING_SIZE, kids_d, positions_d)\n","        kids_d = cp.compress(positions_d, kids_d, axis=0)\n","        del positions_d\n","\n","        if len(kids_d) > 0:\n","            logger.info(f\"{len(kids_d)} new kids found in the {i}-th generation\")\n","\n","            kids_scores_d = evalute_multiple_differences(scenario, num_round, cipher, fitness, len(kids_d), kids_d)\n","\n","            # combine parents and children\n","            gen_d = cp.vstack((gen_d, kids_d))\n","            scores_d = cp.append(scores_d, kids_scores_d)\n","\n","            # keep only those having the best fitness\n","            idxs = cp.argsort(scores_d)[-GENERATION_SIZE:]\n","            gen_d = gen_d[idxs]\n","            scores_d = scores_d[idxs]\n","        else:\n","            logger.warning(f\"no new kids found in the {i}-th generation\")\n","    return gen_d[:GENERATION_SIZE], scores_d[:GENERATION_SIZE]"],"metadata":{"id":"9piNKlyJk9JL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721489760527,"user_tz":-120,"elapsed":3,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}},"outputId":"f2f3d96f-8c8d-4f7e-f560-51446396605f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing evoalgs/evo.py\n"]}]},{"cell_type":"markdown","source":["### fitness/bias_score.py"],"metadata":{"id":"4azk01tQrtKw"}},{"cell_type":"code","source":["%%writefile fitness/bias_score.py\n","\"\"\"\n","Implementation of one of the possible fitness functions: Bias score.\n","\"\"\"\n","# --------------------------------------------------------------------------- #\n","# NOTE:\n","#  A ``_d`` at the end of a variable name indicates that it is saved in the\n","#  device memory of the GPU currently in use.\n","# --------------------------------------------------------------------------- #\n","\n","import cupy as cp\n","import numpy as np\n","\n","from numba import cuda\n","\n","\n","# ---------------------- CONSTANTS -------------------------\n","_LOOP_UNROLLING = 32\n","\"\"\"\n","Number of differences processed per cycle. Do NOT change this value without changing the body of the loop in the kernel.\n","\"\"\"\n","\n","\n","# ---------------------- KERNELS ---------------------------\n","@cuda.jit()\n","def _bias_score(word_size :int, ciphertexts_diffs :cp.ndarray, out :cp.ndarray):\n","    \"\"\"\n","    Compute the bias score for each input difference.\n","    The scores will be saved in ``out``.\n","\n","    Grid & blocks: one block for each input difference, each block contains a number of threads equal to the length of the differences in bits.\n","\n","    Parameters\n","    ----------\n","    ``word_size``: int\n","        Word size in bits of the ciphertexts' differences.\n","    ``ciphertexts_diffs``: cupy.ndarray of shape ``(num_input_diffs, num_output_diffs, num_words)``\n","        Output differences.\n","    ``out``: cupy.ndarray of shape ``(num_input_diffs,)``\n","        Bias scores of each input difference.\n","    \"\"\"\n","    # number of output differences\n","    num_output_diffs = ciphertexts_diffs.shape[1]\n","    # output difference's size in number of words\n","    num_words = ciphertexts_diffs.shape[2]\n","\n","    # word and bit index of the output differences considered by the following thread\n","    word_idx = cuda.threadIdx.x // word_size\n","    bit_idx =  cuda.threadIdx.x % word_size\n","\n","    # constant memory to access words' differences without computing indexes\n","    word_offset = cuda.const.array_like(offsets)\n","\n","    # shared memory for output differences and partial results\n","    smem_diffs = cuda.shared.array(0, dtype=ciphertexts_diffs.dtype)[:num_words*_LOOP_UNROLLING]\n","    smem_res = cuda.shared.array(0, dtype=cp.float32)[-num_words*word_size:]\n","\n","    counter = 0\n","    smem_diffs_offset = smem_diffs[word_idx:]\n","    for i in range(0, num_output_diffs, _LOOP_UNROLLING):\n","        # load in shared memory an output difference\n","        if cuda.threadIdx.x < _LOOP_UNROLLING * num_words:\n","            smem_diffs[cuda.threadIdx.x] = ciphertexts_diffs[cuda.blockIdx.x][i + cuda.threadIdx.x // num_words][cuda.threadIdx.x % num_words]\n","        cuda.syncthreads()\n","\n","        # count bits set to 1 bitwise\n","        if cuda.threadIdx.x < word_size * num_words:\n","            counter += ((smem_diffs_offset[word_offset[0]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[1]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[2]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[3]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[4]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[5]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[6]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[7]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[8]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[9]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[10]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[11]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[12]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[13]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[14]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[15]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[16]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[17]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[18]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[19]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[20]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[21]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[22]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[23]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[24]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[25]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[26]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[27]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[28]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[29]] >> bit_idx) & 1)\n","            counter += ((smem_diffs_offset[word_offset[30]] >> bit_idx) & 1) + ((smem_diffs_offset[word_offset[31]] >> bit_idx) & 1)\n","        cuda.syncthreads()\n","\n","    # scale the partial results\n","    if cuda.threadIdx.x < word_size * num_words:\n","        smem_res[cuda.threadIdx.x] = abs(0.5 - (counter / num_output_diffs))\n","    cuda.syncthreads()\n","\n","    # parallel reduction on 'smem_res'\n","    i = word_size * num_words // 2\n","    while (i > 0):\n","        if (cuda.threadIdx.x < min(word_size * num_words, i)):\n","            smem_res[cuda.threadIdx.x] += smem_res[cuda.threadIdx.x + i]\n","        cuda.syncthreads()\n","        i //= 2\n","\n","    # store the score for the considered input difference in 'out'\n","    if cuda.threadIdx.x == 0:\n","        out[cuda.blockIdx.x] = smem_res[0] / (num_words * word_size)\n","    return\n","\n","\n","# ---------------------- FUNCTIONS -------------------------\n","def evaluate_gpu(word_size :int, ciphertexts_diffs_d :cp.ndarray) -> cp.ndarray:\n","    \"\"\"\n","    Compute the bias score for each input difference.\n","\n","    Parameters\n","    ---------\n","    ``word_size``: int\n","        Word size in bits of the ciphertexts.\n","    ``ciphertexts_diffs_d``: cupy.ndarray of shape ``(num_input_diffs, num_output_diffs, num_words)``\n","        Ciphertexts/output differences.\n","\n","    Returns\n","    -------\n","    ``scores_d``: cupy.ndarray of shape ``(num_input_diffs,)``\n","        Bias scores of each input difference.\n","    \"\"\"\n","    num_input_diffs = ciphertexts_diffs_d.shape[0]\n","    num_output_diffs = ciphertexts_diffs_d.shape[1]\n","    num_word = ciphertexts_diffs_d.shape[2]\n","\n","    if num_output_diffs % _LOOP_UNROLLING != 0:\n","        raise ValueError(f\"invalid number of output differences, it must be a multiple of {_LOOP_UNROLLING}\")\n","\n","    scores_d = cp.zeros(num_input_diffs, dtype=cp.float32)\n","\n","    # array used to init the constant memory\n","    global offsets\n","    offsets = np.array([num_word * i for i in range(_LOOP_UNROLLING)])\n","\n","    # shared memory size in bytes\n","    smem_size = _LOOP_UNROLLING * num_word * ciphertexts_diffs_d.dtype.itemsize + num_word * word_size * scores_d.dtype.itemsize\n","\n","    _bias_score[num_input_diffs, num_word * max(word_size, _LOOP_UNROLLING), 0, smem_size](word_size, ciphertexts_diffs_d, scores_d)\n","    cuda.synchronize()\n","    return scores_d"],"metadata":{"id":"RlgDBNl3r4Vb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721489760527,"user_tz":-120,"elapsed":2,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}},"outputId":"73da5f3f-8dc7-459f-8749-14d290540143"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing fitness/bias_score.py\n"]}]},{"cell_type":"markdown","source":["### optimizer.py"],"metadata":{"id":"_QLY5Z9fr9ig"}},{"cell_type":"code","source":["%%writefile optimizer.py\n","\"\"\"\n","Implementation of the optimizer.\n","\"\"\"\n","# --------------------------------------------------------------------------- #\n","# NOTE:\n","#  A ``_d`` at the end of a variable name indicates that it is saved in the\n","#  device memory of the GPU currently in use.\n","# --------------------------------------------------------------------------- #\n","\n","import cupy as cp\n","import logging\n","\n","from math import ceil\n","from numba import cuda\n","\n","from config import CipherParams, EvoalgParams, FitnessParams\n","from consts import Scenarios\n","from utils.filters import BloomFilterGPU\n","\n","\n","logger = logging.getLogger(\"autond2.\" + __name__)\n","\n","\n","# ---------------------- CONSTANTS -------------------------\n","BIAS_SCORE_THRESHOLD :float = 0.01\n","\"\"\"\n","Do not look for differences for the next round of encryption if the highest score found in the current round is below this threshold.\n","\"\"\"\n","BLOOM_FILTER_SIZE :int = 262_144\n","\"\"\"\n","Bloom filter size in bits. It is used to check the input differences already found by the evolutionary algorithm.\n","\"\"\"\n","BLOOM_FILTER_NUM_HASHES :int = 8\n","\"\"\"\n","Number of hash functions used by the Bloom filter.\n","\"\"\"\n","MAX_DIFFS_PER_ROUND :int = 32\n","\"\"\"\n","Save only the best ``MAX_DIFFS_PER_ROUND`` differences found by the evolutionary algorithm per each round.\n","\"\"\"\n","MAX_ROUND :int = 4\n","\"\"\"\n","Maximum number of cipher rounds tested.\n","\"\"\"\n","NUM_SAMPLES_PER_BATCH :int = 1_048_576\n","\n","\"\"\"\n","Number of samples per batch used to compute the score of each difference.\n","\"\"\"\n","NUM_BATCH :int = 1\n","\"\"\"\n","Number of samples used to compute the score of each difference.\n","\"\"\"\n","\n","\n","# ---------------------- KERNELS ---------------------------\n","@cuda.jit()\n","def _append(pos :cp.ndarray, len_arr1 :int, arr1 :cp.ndarray, len_arr2 :int, arr2 :cp.ndarray):\n","    \"\"\"\n","    Append the elements of ``arr1`` marked in ``pos`` in ``arr2`` starting from the position ``len_arr2``.\n","\n","    Grid & Blocks: bidimensional grid, global shape ``(N, len_arr1)``.\n","\n","    Parameters\n","    ----------\n","    ``pos``: cupy.ndarray of shape ``(len_arr1,)``\n","        Elements of ``arr1`` to be added and in which position of ``arr2`` they must be appended.\n","    ``len_arr1``: int\n","        Number of elements in ``arr1``.\n","    ``arr1``: cupy.ndarray of shape ``(len_arr1, N)``\n","        Elements to be appended.\n","    ``len_arr2``: int\n","        Number of elements in ``arr2``.\n","    ``arr2``: cupy.ndarray of shape ``(len_arr2, N)``\n","        New elements are appended to this array.\n","    \"\"\"\n","    x, y = cuda.grid(2)\n","    if y < len_arr1:\n","        if (y == 0 and pos[y] == 0) or (y != 0 and pos[y] != pos[y-1]):\n","            arr2[len_arr2 + pos[y]][x] = arr1[y][x]\n","    return\n","\n","\n","# ---------------------- FUNCTIONS -------------------------\n","def evalute_multiple_differences(scenario :Scenarios, num_rounds :int, cipher :CipherParams, fitness :FitnessParams, tot_diffs :int, diffs_d :cp.ndarray) -> cp.ndarray:\n","    \"\"\"\n","    Evaluate the given input differences.\n","\n","    Parameters\n","    ----------\n","    ``scenario``: consts.Scenarios\n","        Attack scenario.\n","    ``num_round``: int\n","        Number of rounds to performe during encryption.\n","    ``cipher``: config.CipherParams\n","        Cipher parameters.\n","    ``fitness``: config.FitnessParams\n","        Fitness parameters.\n","    ``tot_diffs``: int\n","        Total number of differences to evaluate.\n","    ``diffs_d``: cupy.ndarray of shape ``(tot_diffs, N)``\n","        Differences to evaluate.\n","\n","    Returns\n","    -------\n","    ``scores_d``: cupy.ndarray of shape ``(tot_diffs,)``\n","        Fitness of each input difference.\n","    \"\"\"\n","    # split input differences into plaintext differences and key differences\n","    plain_diffs_d = diffs_d[:, :cipher.plain_size]\n","    if scenario == Scenarios.SINGLE_KEY:\n","        key_diffs_d = cp.zeros((tot_diffs, cipher.key_size), dtype=cipher.word_type)\n","    elif scenario == Scenarios.RELATED_KEY:\n","        key_diffs_d = diffs_d[:, cipher.plain_size:]\n","\n","    scores_d = cp.zeros(tot_diffs)\n","\n","    for i in range(NUM_BATCH):\n","        # generate random keys and put them in xor with each candidate difference\n","        keys_d = cp.random.randint(1 << cipher.word_size, size=(NUM_SAMPLES_PER_BATCH, cipher.key_size), dtype=cipher.word_type)\n","        keys_xor_diffs_d = (\n","            cp.broadcast_to(key_diffs_d[:, None, :], (tot_diffs, NUM_SAMPLES_PER_BATCH, cipher.key_size)) ^ keys_d\n","        ).reshape(-1, cipher.key_size)\n","\n","        # generate random plaintexts and put them in xor with each candidate difference\n","        plaintexts_d = cp.random.randint(1 << cipher.word_size, size=(NUM_SAMPLES_PER_BATCH, cipher.plain_size), dtype=cipher.word_type)\n","        plaintexts_xor_diffs_d= (\n","            cp.broadcast_to(plain_diffs_d[:, None, :], (tot_diffs, NUM_SAMPLES_PER_BATCH, cipher.plain_size)) ^ plaintexts_d\n","        ).reshape(-1, cipher.plain_size)\n","\n","        # encrypt in-place\n","        cipher.encrypt_func(plaintexts_d, keys_d, 0, num_rounds, cipher.word_size)\n","        cipher.encrypt_func(plaintexts_xor_diffs_d, keys_xor_diffs_d, 0, num_rounds, cipher.word_size)\n","\n","        # free memory\n","        del keys_d, keys_xor_diffs_d\n","\n","        # compute output differences\n","        ciphertexts_differences_d =  plaintexts_xor_diffs_d.reshape(tot_diffs, NUM_SAMPLES_PER_BATCH, -1) ^ plaintexts_d\n","\n","        # free memory\n","        del plaintexts_d, plaintexts_xor_diffs_d\n","\n","        # compute a score for each input differences considering the output differeces produced\n","        scores_d += fitness.evaluate_func(cipher.word_size, ciphertexts_differences_d)\n","    return scores_d\n","\n","\n","def merge_unique(tot_diffs :int, diffs_d :cp.ndarray, tot_all_diffs :int, all_diffs_d :cp.ndarray, all_diffs_filter :BloomFilterGPU) -> int:\n","    \"\"\"\n","    Merge the given input differences in ``diffs_d`` in ``all_diffs_d``, removing the duplicates.\n","\n","    Parameters\n","    ----------\n","    ``tot_diffs``: int\n","        Total number of differences to merge.\n","    ``diffs_d``: cupy.ndarray of shape ``(tot_diffs, N)``\n","        Differences to merge.\n","    ``tot_all_diffs``: int\n","        Total number of differences in ``all_diffs_d``.\n","    ``all_diffs_d``: cupy.ndarray of shape ``(MAX_DIFFS_PER_ROUND * MAX_ROUND, N)``\n","        Unique differences already found by the evolutionary algorithm.\n","    ``all_diffs_filter``: BloomFilter\n","        Bloom filter used to check the input differences already found by the evolutionary algorithm.\n","\n","    Returns\n","    -------\n","    ``tot_all_diffs``: int\n","        New total number of differences in ``all_diffs_d``.\n","    \"\"\"\n","    if diffs_d.shape[1] != all_diffs_d.shape[1]:\n","        raise ValueError(\"``diffs_d`` and ``all_diffs_d``: mismatched shapes\")\n","    len_diff = diffs_d.shape[1]\n","\n","    # i-th entry will be '1' iif the difference 'diffs_d[i]' is not in 'all_diffs_d'\n","    positions_d = cp.zeros(tot_diffs, dtype=cp.int64)\n","\n","    # add differences in the bloom filter and return in 'positions_d' those not already seen\n","    all_diffs_filter.insert_new_elements(tot_diffs, diffs_d, positions_d)\n","\n","    # positions where the new differences will be appended.\n","    positions_d = positions_d.cumsum() - 1\n","\n","    block = (len_diff, min(1024 // len_diff, tot_diffs))\n","    grid = (1, ceil(tot_diffs / block[1]))\n","    _append[grid, block](positions_d, tot_diffs, diffs_d, tot_all_diffs, all_diffs_d)\n","    cuda.synchronize()\n","\n","    tot_all_diffs += int(positions_d[-1]) + 1\n","    return tot_all_diffs\n","\n","\n","def optimize(scenario :Scenarios, cipher :CipherParams, evoalg :EvoalgParams, fitness :FitnessParams) -> tuple[cp.ndarray, cp.ndarray, cp.ndarray, cp.ndarray]:\n","    \"\"\"\n","    Find good input differences for a differential attack.\n","\n","    Parameters\n","    ----------\n","    ``scenario``: consts.Scenarios\n","        Attack scenario.\n","    ``cipher``: config.CipherParams\n","        Cipher parameters.\n","    ``evoalg``: config.EvoalgParams\n","        Evolutionary algorithm parameters.\n","    ``fitness``: config.FitnessParams\n","        Fitness parameters.\n","\n","    Returns\n","    -------\n","    ``(all_diffs_d, final_scores_d, weighted_scores_d, cumulative_scores_d)``: tuple[cupy.ndarray, cupy.ndarray, cupy.ndarray, cupy.ndarray] of shapes ``(tot_all_diffs, tot_words)``, ``(round, tot_all_diffs)``, ``(tot_all_diffs,)``, ``(tot_all_diffs,)``\n","        Best input differences found and their scores for each round of encryption test, their weighted scores and their cumulative scores.\n","    \"\"\"\n","    if scenario == Scenarios.SINGLE_KEY:\n","        tot_words = cipher.plain_size\n","    elif scenario == Scenarios.RELATED_KEY:\n","        tot_words = cipher.plain_size + cipher.key_size\n","\n","    tot_all_diffs = 0\n","    all_diffs_filter = BloomFilterGPU(BLOOM_FILTER_NUM_HASHES, BLOOM_FILTER_SIZE)\n","    all_diffs_d = cp.empty((MAX_DIFFS_PER_ROUND * MAX_ROUND, tot_words), dtype=cipher.word_type)\n","\n","    rounds = 0\n","    while True:\n","        rounds += 1\n","\n","        diffs_d, scores_d = evoalg.evolve_func(scenario, rounds, cipher, fitness)\n","        tot_diffs, cur_best_score = min(diffs_d.shape[0], MAX_DIFFS_PER_ROUND), float(scores_d[-1])\n","        diffs_d = diffs_d[-tot_diffs:]\n","\n","        tot_all_diffs = merge_unique(tot_diffs, diffs_d, tot_all_diffs, all_diffs_d, all_diffs_filter)\n","\n","        logger.info(f\"round {rounds} - best score:{round(cur_best_score, 4)}, tot_diffs:{tot_diffs}, tot_all_diffs:{tot_all_diffs}\")\n","        if (cur_best_score < BIAS_SCORE_THRESHOLD) or (rounds >= MAX_ROUND):\n","            break\n","\n","    del all_diffs_filter\n","    all_diffs_d = all_diffs_d[:tot_all_diffs]\n","\n","    # re-evaluate all the differences found\n","    final_scores_d = [None for i in range(rounds)]\n","    weighted_scores_d = cp.zeros(tot_all_diffs, dtype=cp.float32)\n","    cumulative_scores_d = cp.zeros(tot_all_diffs, dtype=cp.float32)\n","\n","    for i in range(0, rounds):\n","        scores_d = evalute_multiple_differences(scenario, i+1, cipher, fitness, tot_all_diffs, all_diffs_d)\n","        final_scores_d[i] = scores_d\n","        weighted_scores_d += (i+1 * scores_d)\n","        cumulative_scores_d += scores_d\n","\n","    return all_diffs_d, final_scores_d, weighted_scores_d, cumulative_scores_d"],"metadata":{"id":"8vAJXwUp57hO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721489760527,"user_tz":-120,"elapsed":2,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}},"outputId":"614c4b7a-1f5d-406f-a051-3d37295f5d4e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing optimizer.py\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"n7OPvqxmICZ1"}},{"cell_type":"code","source":["import cupy as cp\n","import logging\n","import warnings\n","\n","from ciphers.speck import encrypt\n","from evoalgs.evo import evolve_gpu\n","from fitness.bias_score import evaluate_gpu\n","\n","from config import CipherParams, EvoalgParams, FitnessParams\n","from consts import Scenarios\n","from optimizer import optimize\n","\n","\n","warnings.filterwarnings('ignore')\n","\n","logging.basicConfig(format='%(asctime)s:%(levelname)s:%(name)s:%(funcName)s:%(message)s')\n","for name in logging.root.manager.loggerDict:\n","    if name.startswith('autond2'):\n","        logging.getLogger(name).setLevel(logging.INFO)\n","\n","cipher = CipherParams(None, encrypt, 3, 2, 32, cp.uint32)\n","evoalg = EvoalgParams(None, evolve_gpu)\n","fitness = FitnessParams(None, evaluate_gpu)\n","\n","diffs, f, w, c = optimize(Scenarios.SINGLE_KEY, cipher, evoalg, fitness)\n","\n","print(diffs)\n","print(f[0])"],"metadata":{"id":"FGbEg3xZSCWi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721489821595,"user_tz":-120,"elapsed":61070,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}},"outputId":"0fb307dc-1834-4e0a-d5f7-d0c834cb82de"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:autond2.utils.filters:filter <utils.filters.BloomFilterGPU object at 0x7be723d9e2f0> has an error probability of 1% after 27077 entries\n","INFO:autond2.utils.filters:filter <utils.filters.BloomFilterGPU object at 0x7be726109c30> has an error probability of 1% after 27077 entries\n","INFO:autond2.evoalgs.evo:128 new kids found in the 0-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 1-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 2-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 3-th generation\n","INFO:autond2.evoalgs.evo:127 new kids found in the 4-th generation\n","INFO:autond2.evoalgs.evo:127 new kids found in the 5-th generation\n","INFO:autond2.evoalgs.evo:125 new kids found in the 6-th generation\n","INFO:autond2.evoalgs.evo:118 new kids found in the 7-th generation\n","INFO:autond2.evoalgs.evo:113 new kids found in the 8-th generation\n","INFO:autond2.evoalgs.evo:116 new kids found in the 9-th generation\n","INFO:autond2.optimizer:round 1 - best score:0.4531, tot_diffs:32, tot_all_diffs:32\n","INFO:autond2.utils.filters:filter <utils.filters.BloomFilterGPU object at 0x7be716d9feb0> has an error probability of 1% after 27077 entries\n","INFO:autond2.evoalgs.evo:128 new kids found in the 0-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 1-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 2-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 3-th generation\n","INFO:autond2.evoalgs.evo:127 new kids found in the 4-th generation\n","INFO:autond2.evoalgs.evo:126 new kids found in the 5-th generation\n","INFO:autond2.evoalgs.evo:124 new kids found in the 6-th generation\n","INFO:autond2.evoalgs.evo:117 new kids found in the 7-th generation\n","INFO:autond2.evoalgs.evo:117 new kids found in the 8-th generation\n","INFO:autond2.evoalgs.evo:99 new kids found in the 9-th generation\n","INFO:autond2.optimizer:round 2 - best score:0.3823, tot_diffs:32, tot_all_diffs:61\n","INFO:autond2.utils.filters:filter <utils.filters.BloomFilterGPU object at 0x7be710398a60> has an error probability of 1% after 27077 entries\n","INFO:autond2.evoalgs.evo:128 new kids found in the 0-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 1-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 2-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 3-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 4-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 5-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 6-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 7-th generation\n","INFO:autond2.evoalgs.evo:125 new kids found in the 8-th generation\n","INFO:autond2.evoalgs.evo:127 new kids found in the 9-th generation\n","INFO:autond2.optimizer:round 3 - best score:0.1514, tot_diffs:32, tot_all_diffs:91\n","INFO:autond2.utils.filters:filter <utils.filters.BloomFilterGPU object at 0x7be5e1a93010> has an error probability of 1% after 27077 entries\n","INFO:autond2.evoalgs.evo:128 new kids found in the 0-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 1-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 2-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 3-th generation\n","INFO:autond2.evoalgs.evo:127 new kids found in the 4-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 5-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 6-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 7-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 8-th generation\n","INFO:autond2.evoalgs.evo:128 new kids found in the 9-th generation\n","INFO:autond2.optimizer:round 4 - best score:0.1146, tot_diffs:32, tot_all_diffs:122\n"]},{"output_type":"stream","name":"stdout","text":["[[ 268574722   33555456]\n"," [    131072 1078460418]\n"," [1342439488    4720640]\n"," [2147647488 1073741826]\n"," [ 272631808    4718592]\n"," [1073741888   38273026]\n"," [ 276955136    4718592]\n"," [1342177796    4718592]\n"," [    131110          2]\n"," [1082327104          0]\n"," [ 273023040          0]\n"," [ 268566530    1049104]\n"," [   8781824   33572352]\n"," [    139298        512]\n"," [3221225555          0]\n"," [ 268566544       2560]\n"," [1073872897    4718592]\n"," [1077936145   16777216]\n"," [      8256    4718624]\n"," [    393232          2]\n"," [1342177792    4718594]\n"," [ 268697600    4718592]\n"," [      4176 1107296256]\n"," [    139266          0]\n"," [        16       4098]\n"," [   4325392          0]\n"," [    131090          0]\n"," [    131074    8388608]\n"," [         2   38273024]\n"," [    131138          0]\n"," [ 268435456          2]\n"," [      8384 1073741824]\n"," [     16450  603979784]\n"," [ 603979780     524292]\n"," [    132160   67371008]\n"," [  67113028    1048576]\n"," [  37769280          0]\n"," [ 536870914 1078001664]\n"," [  67108868 2147491840]\n"," [      4096    4980736]\n"," [  33636352    1048576]\n"," [      4100 2147491840]\n"," [         0 1075314704]\n"," [  83886084 2148073472]\n"," [  67239940     524288]\n"," [        66 1078460416]\n"," [  67112966          0]\n"," [         0 1074266116]\n"," [    524304    1572864]\n"," [       128  603979784]\n"," [        64   68943872]\n"," [  67108866         64]\n"," [  33587200    1048576]\n"," [      4160 1077936128]\n"," [  33558528      16384]\n"," [  67108868    1572864]\n"," [    524288      73728]\n"," [  67108900          0]\n"," [         2       8192]\n"," [  67108864        256]\n"," [     65536 2147483648]\n"," [   2097152  133744752]\n"," [1415724130          0]\n"," [2854087136        128]\n"," [         0  105192118]\n"," [2923293152 1621763177]\n"," [3155271425 2238126870]\n"," [1413659746         16]\n"," [ 336541581   67108866]\n"," [1761945668    2097776]\n"," [ 338630533          4]\n"," [3975708764 3576168233]\n"," [2772562113          0]\n"," [2426319880         16]\n"," [3355621537   67108864]\n"," [3187688551   67108864]\n"," [2820548740    2097760]\n"," [3235403864    2105344]\n"," [1073922937        512]\n"," [ 336533381         32]\n"," [1947412392     262144]\n"," [1979907270       4096]\n"," [ 857494656       8192]\n"," [ 956820285 2107967481]\n"," [2600631300      65536]\n"," [2030381124          0]\n"," [2585935364  134217728]\n"," [ 336533381          0]\n"," [2970063077        128]\n"," [1612451877   67108960]\n"," [2820581508         16]\n"," [3677641595 3519555498]\n"," [1744090573 4067151162]\n"," [2741880886 3061230300]\n"," [3426029902 2303855260]\n"," [  20936711 3742893327]\n"," [4189167396 1305693640]\n"," [3729598160 3742543035]\n"," [ 606895569 1317980193]\n"," [3873236704 4078025589]\n"," [1533156716 3801225950]\n"," [ 338813658 2367956485]\n"," [1711520333 1032461761]\n"," [ 722064132 1858210284]\n"," [3697844806 1939432148]\n"," [3259479415 1451065407]\n"," [ 809631396  241710067]\n"," [1248802765 3247185286]\n"," [1673517196 4146444160]\n"," [4060498898 1939432148]\n"," [1200858461 3216539894]\n"," [4171658019 3282759205]\n"," [1951855434  150458119]\n"," [ 791447136 3758828257]\n"," [ 987874900  418893575]\n"," [1613397313          0]\n"," [ 256612336 3075428337]\n"," [3387973760          0]\n"," [ 728727553 3758828257]\n"," [3532705824      65536]\n"," [1174650914          0]\n"," [         0      65536]]\n","[0.36292577 0.36363468 0.3674539  0.36800963 0.36833504 0.3687081\n"," 0.36970541 0.37063184 0.37134996 0.37588832 0.37750965 0.37762609\n"," 0.37854469 0.38676918 0.38679454 0.38698491 0.38800746 0.38931653\n"," 0.39468107 0.39476925 0.39852449 0.39860594 0.4063164  0.40870184\n"," 0.41026348 0.41115612 0.41409138 0.41458103 0.41465026 0.42288005\n"," 0.43758008 0.45313397 0.3672829  0.36918214 0.36184502 0.36973271\n"," 0.37133583 0.38098335 0.40831745 0.39461994 0.38695064 0.40731317\n"," 0.40647003 0.399645   0.39188075 0.39992121 0.39198309 0.42194128\n"," 0.39484966 0.41800123 0.39311528 0.40704933 0.41032755 0.42212611\n"," 0.41028368 0.40778801 0.41799676 0.41812828 0.43798721 0.43757647\n"," 0.46880773 0.21496513 0.21491531 0.1931828  0.20434222 0.19979277\n"," 0.18189669 0.2198087  0.21519259 0.2389653  0.2130461  0.16285515\n"," 0.24728546 0.22774065 0.25804329 0.25022832 0.2593374  0.22224995\n"," 0.27073157 0.2182067  0.20881528 0.18281311 0.25996402 0.22966459\n"," 0.23972881 0.24673378 0.21098882 0.23189867 0.23124403 0.264882\n"," 0.23976794 0.13596416 0.12905401 0.16143718 0.11163384 0.14455879\n"," 0.11544198 0.1008074  0.11933589 0.12133944 0.12818778 0.1347625\n"," 0.12766698 0.14935201 0.14379019 0.12233382 0.20482248 0.14655739\n"," 0.19500884 0.12236929 0.12520012 0.15910655 0.14028683 0.20507601\n"," 0.15197775 0.2234267  0.17144835 0.28984717 0.19968012 0.25172019\n"," 0.29709509 0.46884909]\n"]}]},{"cell_type":"markdown","source":["## **Nsight Systems**"],"metadata":{"id":"XHXcGOM8CBIA"}},{"cell_type":"markdown","source":["Codice per produrre report Nsight Systems."],"metadata":{"id":"Ffb4YNMoy5uy"}},{"cell_type":"code","source":["##import locale\n","\n","##def getpreferredencoding(do_setlocale = True):\n","##    return \"UTF-8\"\n","##locale.getpreferredencoding = getpreferredencoding\n","\n","##with open(\"main.py\", \"w\") as f:\n","##  f.write(str(In[7]))\n","\n","##!nsys profile \\\n","##  --trace cuda,osrt,nvtx \\\n","##  --gpu-metrics-device=all \\\n","##  --cuda-memory-usage true \\\n","##  --force-overwrite true \\\n","##  --output ../profile_main \\\n","##  python main.py"],"metadata":{"id":"dYfPDWO51gkl","executionInfo":{"status":"ok","timestamp":1721489821595,"user_tz":-120,"elapsed":4,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## **Extras**"],"metadata":{"id":"0X35RrTaszqe"}},{"cell_type":"markdown","source":["Kernel alternativo per il calcolo del *bias score* :"],"metadata":{"id":"knoz9BHqys_m"}},{"cell_type":"code","source":["##import cupy as cp\n","##import numpy as np\n","\n","# ---------------------- KERNELS ---------------------------\n","##@cuda.jit()\n","##def _bias_score(word_size :int, ciphertexts_diffs :cp.ndarray, out :cp.ndarray):\n","    # number of output differences\n","    ##num_output_diffs = ciphertexts_diffs.shape[1]\n","    # output difference's size in number of words\n","    ##num_words = ciphertexts_diffs.shape[2]\n","\n","    # word and bit index of the output differences considered\n","    # by the following thread\n","    ##word_idx = cuda.blockIdx.y // word_size\n","    ##bit_idx =  cuda.blockIdx.y % word_size\n","\n","\n","    # shared memory\n","    ##smem = cuda.shared.array(0, dtype=out.dtype)\n","    ##smem[cuda.threadIdx.x] = 1 if ciphertexts_diffs[cuda.blockIdx.z][word_idx][cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x] & (1 << bit_idx) else 0\n","    ##cuda.syncthreads()\n","\n","    # parallel reduction on 'smem_res'\n","    ##i = cuda.blockDim.x // 2\n","    ##while (i > 0):\n","        ##if (cuda.threadIdx.x < i):\n","            ##smem[cuda.threadIdx.x] += smem[cuda.threadIdx.x + i]\n","        ##cuda.syncthreads()\n","        ##i //= 2\n","\n","\n","    # store the score for the considered input difference in 'out'\n","    ##if cuda.threadIdx.x == 0:\n","        ##out[cuda.blockIdx.z][cuda.blockIdx.y][cuda.blockIdx.x] = smem[0]\n","    ##return\n","\n","\n","# ---------------------- FUNCTIONS -------------------------\n","##def evaluate_gpu(word_size :int, ciphertexts_diffs_d :cp.ndarray) -> cp.ndarray:\n","    ##num_input_diffs = ciphertexts_diffs_d.shape[0]\n","    ##num_output_diffs = ciphertexts_diffs_d.shape[1]\n","    ##num_word = ciphertexts_diffs_d.shape[2]\n","\n","    # thread per block\n","    ##t = 256\n","\n","    ##scores_d = cp.zeros((num_input_diffs, num_word * word_size, num_output_diffs // t), dtype=cp.float32)\n","\n","    # shared memory size in bytes\n","    ##smem_size = t * scores_d.dtype.itemsize\n","    ##grid, block = (num_output_diffs // t, num_word * word_size, num_input_diffs), t\n","    ##_bias_score[grid, block, 0, smem_size](word_size, ciphertexts_diffs_d, scores_d)\n","    ##cuda.synchronize()\n","\n","    ##scores_d = cp.mean(cp.abs(0.5 - cp.sum(scores_d, axis=2) / num_output_diffs), axis=1)\n","    ##return scores_d"],"metadata":{"id":"B_SgKaW5tF9g","executionInfo":{"status":"ok","timestamp":1721489854706,"user_tz":-120,"elapsed":2,"user":{"displayName":"Matteo Onger","userId":"14345067660125991616"}}},"execution_count":10,"outputs":[]}]}